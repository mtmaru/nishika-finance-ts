# Nishika 金融時系列予測コンペ 25th Place Solution

Nishika「[金融時系列予測](https://competition.nishika.com/competitions/finance\_ts/summary)」の25th place solution です。

## 解法の概要

- アイデア
    - 学習データとテストデータの分布が異なることへの対策として、学習データからテストデータっぽいデータ点だけを選ぶことで学習データの分布をテストデータに近づけました。
- 手順
    1. 学習データとテストデータの判別器を作る (※adversarial validationに相当)。
    2. 手順1で作った判別器を用いて、学習データの各点が学習データである確率・テストデータである確率を求める。
    3. 手順2で求めた確率をもとに、学習データの各点の重要度を求める。
        - 重要度 = (テストデータである確率 / テストデータ数) / (学習データである確率 / 学習データ数)
    4. 手順3で求めた重要度を各データ点の重みとして設定し、学習を行う。
- 工夫・注意点
    - 手順1～3はリークを防ぐため、target encodingの要領でCVを組み合わせて実行しました。
    - 手順1の判別器の出力を確率とみなして手順2以降を実行するので、cross entropyの代わりにcalibrationの効果があるfocal lossを用いて判別器を学習させました。
- 所管
    - 私が試した解法の中では一応本解法が最もprivateスコアが良かったのですが、一方で手元のCVやpublicスコアの改善にはつながりませんでしたし、他の方の解法を見ても分布の違いを吸収することが必ずしも必要なわけではなさそうだったので、正直今回のコンペで効く解法ではなかったかな……と思いました。

## コード

- [nishika-fts-lgb.ipynb](./nishika-fts-lgb.ipynb)

## 重み付けの妥当性と重要度の導出

なぜ重み付けするとテストデータに近づくのかと、なぜ重要度の式がこうなるのかを以下で補足します。

### 共変量シフト下における過学習

まず、記号を定義しておきます。

サンプルサイズ $N$ の学習データに含まれるデータ点 $n$ の説明変数を $x\_n$、目的変数の実測値を $y\_n$、目的変数の予測値を $\hat{y}\_n = f(x\_n, \theta)$ (※ $\theta$ はモデルのパラメーターです)、実測値と予測値の誤差を $l(y\_n, \hat{y}\_n)$ と置きます。例えば、MSEなら $l(y\_n, \hat{y}\_n) = (y\_n - \hat{y}\_n)^2$ です。

このとき、損失関数 $L$ を以下のように定義します。

$$
L=\frac{1}{N}\sum\_{n=1}^{N}{l(y\_n, \hat{y}\_n)}
$$

多くの機械学習の手法では、この損失関数 $L$ を最小化するパラメーター $\hat{\theta}$ を求めることを学習のゴールとしています。

$$
\hat{\theta}=\text{argmin}\_{\theta}{L}
$$

この損失関数 $L$ ですが、汎化誤差 (学習データに含まれない未知のデータ点を含む、全データ点に対する誤差の期待値) をモンテカルロ法で近似したものとみなすことができます。

$$
L
=\frac{1}{N}\sum\_{n=1}^{N}{l(y\_n, \hat{y}\_n)}
\approx\int{\int{l(y,\hat{y})p(y\mid x)p(x)}dx}dy
$$

ここで問題になるのが説明変数 $x$ の生成分布 $p(x)$ です。上記の近似では、学習データもテストデータも共通の生成分布 $p(x)$ からサンプリングされたものであると仮定しています。しかし、現実的には学習データとテストデータの分布が一致するとは限りません。学習データの生成分布を $p(x\mid\text{train})$、テストデータの生成分布を $p(x\mid\text{test})$ とすると、学習データとテストデータの誤差の期待値は以下のように表せます。

$$
G\_{\text{train}}=\int{\int{l(y,\hat{y})p(y\mid x)p(x\mid\text{train})}dx}dy
$$

$$
G\_{\text{test}}=\int{\int{l(y,\hat{y})p(y\mid x)p(x\mid\text{test})}dx}dy
$$

$$
L\approx G\_{\text{train}}\ne G\_{\text{test}}
$$

我々はテストデータに対する予測精度が高いモデルを作ろうとしているので $G\_{\text{test}}$ を最小化しなければならないのですが、一方で $L$ は $G\_{\text{train}}$ を近似しているので $L$ を最小化しても $G\_{\text{test}}$ を最小化できるとは限りません。これが共変量シフト下における過学習です。

※上記議論では「説明変数と目的変数の関係 $p(y \mid x)$ は、学習データとテストデータで共通している」と仮定している点に注意してください。今回のコンペのような時系列データの場合、 $p(y \mid x)$ すらも学習データとテストデータで異なっているのが普通です。例えば目的変数にトレンドが生じている場合、説明変数の値が同じでも時刻が異なれば目的変数の値は異なります。

### 損失関数の補正

過学習を防ぎたいので、 $L$ を $G\_{\text{test}}$ に近づける方法を考えます。

$G\_{\text{train}}$ と $G\_{\text{test}}$ の違いは説明変数 $x$ の生成分布だけなので、もし学習データとテストデータの密度比を何らかの方法で求めることができれば、その密度比を $G\_{\text{train}}$ にかけることで $G\_{\text{test}}$ へ変換できます。したがって、過学習を防ぐには、損失関数 $L$ を最小化する代わりに、学習データとテストデータの密度比で重み付けした損失関数 $L\_w$ を最小化すればよいことがわかります。



$$
\begin{align*}
L\_w&=\frac{1}{N}\sum\_{n=1}^{N}{\frac{p(x\_n \mid \text{test})}{p(x\_n \mid \text{train})} l(y\_n, \hat{y}\_n)} \\
&\approx\int{\int{\frac{p(x \mid \text{test})}{p(x \mid \text{train})} l(y,\hat{y})p(y\mid x)p(x\mid \text{train})}dx}dy \\
&=\int{\int{l(y,\hat{y})p(y\mid x)p(x\mid \text{test})}dx}dy \\
&=G\_{\text{test}}
\end{align*}
$$

学習データとテストデータの密度比を求める方法はいろいろ提案されていますが (”密度比推定” で調べてみてください)、ここでは最も単純な方法であるadversarial validationを用いた方法を紹介します。

ベイズの定理を使うと、密度比は以下のように変形できます。

$$
\frac{p(x \mid \text{test})}{p(x \mid \text{train})}
=\frac{\frac{p(x, \text{test})}{p(\text{test})}}{\frac{p(x, \text{train})}{p(\text{train})}}
=\frac{\frac{p(x, \text{test})}{p(x)p(\text{test})}}{\frac{p(x, \text{train})}{p(x)p(\text{train})}}
=\frac{\frac{p(\text{test} \mid x)}{p(\text{test})}}{\frac{p(\text{train} \mid x)}{p(\text{train})}}
$$

$p(\text{test} \mid x)$ は説明変数 $x$ がテストデータである確率を表しているので、adversarial validationの要領で学習データとテストデータの判別器を作れば求められます。また、 $p(\text{test})$ は単にテストデータの割合を表しているので、テストデータの件数を数えれば求められます。 $p(\text{train} \mid x)$ や $p(\text{train})$ も同様です。

以上から、学習データとテストデータの分布が異なる場合には以下の手順を踏むことでテストデータに対する誤差を最小化するようなパラメーターを求めることができます。

1. adversarial validationを用いて学習データとテストデータの密度比を求める。
2. その密度比を損失関数の重みとして設定し学習させる。
