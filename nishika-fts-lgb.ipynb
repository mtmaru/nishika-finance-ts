{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6333687,"sourceType":"datasetVersion","datasetId":3608733,"isSourceIdPinned":true}],"dockerImageVersionId":30527,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Nishika 金融時系列予測","metadata":{}},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"## セットアップ","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import StratifiedKFold\nimport lightgbm as lgb","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-14T00:44:22.878632Z","iopub.execute_input":"2023-09-14T00:44:22.879390Z","iopub.status.idle":"2023-09-14T00:44:22.883766Z","shell.execute_reply.started":"2023-09-14T00:44:22.879348Z","shell.execute_reply":"2023-09-14T00:44:22.882850Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('train.csv')\ntest = pd.read_csv('test.csv')","metadata":{"execution":{"iopub.status.busy":"2023-09-14T00:44:22.885885Z","iopub.execute_input":"2023-09-14T00:44:22.886632Z","iopub.status.idle":"2023-09-14T00:44:24.337379Z","shell.execute_reply.started":"2023-09-14T00:44:22.886596Z","shell.execute_reply":"2023-09-14T00:44:24.336442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 前処理","metadata":{}},{"cell_type":"code","source":"# Focal loss implementation for LightGBM\n# https://maxhalford.github.io/blog/lightgbm-focal-loss/\n\nimport numpy as np\nfrom scipy import optimize\nfrom scipy import special\n\nclass FocalLoss:\n    def __init__(self, gamma, alpha=None):\n        self.alpha = alpha\n        self.gamma = gamma\n\n    def at(self, y):\n        if self.alpha is None:\n            return np.ones_like(y)\n        return np.where(y, self.alpha, 1 - self.alpha)\n\n    def pt(self, y, p):\n        p = np.clip(p, 1e-15, 1 - 1e-15)\n        return np.where(y, p, 1 - p)\n\n    def __call__(self, y_true, y_pred):\n        at = self.at(y_true)\n        pt = self.pt(y_true, y_pred)\n        return -at * (1 - pt) ** self.gamma * np.log(pt)\n\n    def grad(self, y_true, y_pred):\n        y = 2 * y_true - 1  # {0, 1} -> {-1, 1}\n        at = self.at(y_true)\n        pt = self.pt(y_true, y_pred)\n        g = self.gamma\n        return at * y * (1 - pt) ** g * (g * pt * np.log(pt) + pt - 1)\n\n    def hess(self, y_true, y_pred):\n        y = 2 * y_true - 1  # {0, 1} -> {-1, 1}\n        at = self.at(y_true)\n        pt = self.pt(y_true, y_pred)\n        g = self.gamma\n\n        u = at * y * (1 - pt) ** g\n        du = -at * y * g * (1 - pt) ** (g - 1)\n        v = g * pt * np.log(pt) + pt - 1\n        dv = g * np.log(pt) + g + 1\n\n        return (du * v + u * dv) * y * (pt * (1 - pt))\n\n    def init_score(self, y_true):\n        res = optimize.minimize_scalar(\n            lambda p: self(y_true, p).sum(),\n            bounds=(0, 1),\n            method='bounded'\n        )\n        p = res.x\n        log_odds = np.log(p / (1 - p))\n        return log_odds\n\n    def lgb_obj(self, preds, train_data):\n        y = train_data.get_label()\n        p = special.expit(preds)\n        return self.grad(y, p), self.hess(y, p)\n\n    def lgb_eval(self, preds, train_data):\n        y = train_data.get_label()\n        p = special.expit(preds)\n        is_higher_better = False\n        return 'focal_loss', self(y, p).mean(), is_higher_better","metadata":{"execution":{"iopub.status.busy":"2023-09-14T00:44:25.175642Z","iopub.execute_input":"2023-09-14T00:44:25.176267Z","iopub.status.idle":"2023-09-14T00:44:25.199088Z","shell.execute_reply.started":"2023-09-14T00:44:25.176234Z","shell.execute_reply":"2023-09-14T00:44:25.197492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def estimate_loss_importance(train, test, x_columns):\n    traintest = pd.concat([\n        train.assign(is_test=0),\n        test.assign(is_test=1)\n    ], ignore_index=True)\n    traintest['p_test'] = 0.0\n\n    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n    fl = FocalLoss(alpha=None, gamma=3)\n    for fold, (train_index, test_index) in enumerate(skf.split(traintest, traintest['is_test'])):\n        model = lgb.train(\n            params = {\n                'metric': 'auc',\n                'learning_rate': 0.05,\n                'feature_fraction': 0.8,\n                'verbose': -1\n            },\n            fobj = fl.lgb_obj,\n            num_boost_round = 200,\n            train_set = lgb.Dataset(\n                data = traintest.loc[train_index, x_columns],\n                label = traintest.loc[train_index, 'is_test'],\n                init_score = np.full_like(\n                    traintest.loc[train_index, 'is_test'],\n                    fl.init_score(traintest.loc[train_index, 'is_test']),\n                    dtype = float\n                )\n            ),\n            valid_sets = [\n                lgb.Dataset(\n                    data = traintest.loc[test_index, x_columns],\n                    label = traintest.loc[test_index, 'is_test'],\n                    init_score = np.full_like(\n                        traintest.loc[test_index, 'is_test'],\n                        fl.init_score(traintest.loc[test_index, 'is_test']),\n                        dtype = float\n                    )\n                )\n            ],\n            callbacks = [\n                lgb.log_evaluation(10)\n            ]\n        )\n        traintest.loc[test_index, 'p_test'] = special.expit(\n            fl.init_score(traintest.loc[train_index, 'is_test']) +\n            model.predict(traintest.loc[test_index, x_columns])\n        )\n\n    traintest['p_train'] = 1 - traintest['p_test']\n    traintest['importance'] = (traintest['p_test'] / test.shape[0]) / (traintest['p_train'] / train.shape[0])\n\n    return train[['id']].merge(traintest[['id', 'importance']], how='left', on='id')['importance'].to_numpy()","metadata":{"execution":{"iopub.status.busy":"2023-09-14T00:44:25.203200Z","iopub.execute_input":"2023-09-14T00:44:25.203746Z","iopub.status.idle":"2023-09-14T00:44:25.225757Z","shell.execute_reply.started":"2023-09-14T00:44:25.203692Z","shell.execute_reply":"2023-09-14T00:44:25.224907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['group'] = train['id'] // 10000\nx_columns = train.columns.drop(['id', 'target', 'group']).to_list()\n\ntrain['importance'] = estimate_loss_importance(train, test, x_columns)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T00:44:25.226972Z","iopub.execute_input":"2023-09-14T00:44:25.227584Z","iopub.status.idle":"2023-09-14T00:44:55.832026Z","shell.execute_reply.started":"2023-09-14T00:44:25.227539Z","shell.execute_reply":"2023-09-14T00:44:55.830682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 学習","metadata":{}},{"cell_type":"code","source":"models = []\nfor seed in range(10):\n    print(seed)\n    train_sample = train.sample(frac=0.8, random_state=seed)\n    model = lgb.train(\n        params = {\n            'objective': 'regression',\n            'learning_rate': 0.05,\n            'feature_fraction': 0.8,\n            'verbose': -1\n        },\n        num_boost_round = 400,\n        train_set = lgb.Dataset(\n            data = train_sample[x_columns],\n            label = train_sample['target'],\n            weight = train_sample['importance'] ** 1.0\n        )\n    )\n    models.append(model)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T00:44:55.833473Z","iopub.execute_input":"2023-09-14T00:44:55.833787Z","iopub.status.idle":"2023-09-14T00:45:38.977896Z","shell.execute_reply.started":"2023-09-14T00:44:55.833759Z","shell.execute_reply":"2023-09-14T00:45:38.976397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 予測","metadata":{}},{"cell_type":"code","source":"test_y_pred = np.mean([model.predict(test[x_columns]) for model in models], axis=0)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T00:45:38.979760Z","iopub.execute_input":"2023-09-14T00:45:38.980145Z","iopub.status.idle":"2023-09-14T00:45:39.073730Z","shell.execute_reply.started":"2023-09-14T00:45:38.980112Z","shell.execute_reply":"2023-09-14T00:45:39.072382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 提出用ファイルの作成","metadata":{}},{"cell_type":"code","source":"pd.DataFrame({'id': test['id'], 'target': test_y_pred}).to_csv('submission.csv', index=False, header=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T00:45:39.075477Z","iopub.execute_input":"2023-09-14T00:45:39.075830Z","iopub.status.idle":"2023-09-14T00:45:39.086248Z","shell.execute_reply.started":"2023-09-14T00:45:39.075799Z","shell.execute_reply":"2023-09-14T00:45:39.085084Z"},"trusted":true},"execution_count":null,"outputs":[]}]}